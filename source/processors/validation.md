---
description: Справка по валидации моделей в Loginom. Формирование обучающего и тестового множества для обучения аналитической модели. Работа без валидации, метод кросс-валидации K-folds, метод валидации Монте-Карло.
---
# Валидация моделей

**Валидация** — проверка правильности работы (предсказательной способности) аналитической модели, построенной на основе машинного обучения, а также удостоверение, что она соответствует требованиям решаемой задачи.

Проводится на независимом (т.е. не использовавшемся для обучения и тестирования) валидационном множестве после обучения и тестирования модели.

## Варианты валидации

### Без валидации

Валидация не производится.

### Метод кросс-валидации K-folds

Метод формирования обучающего и тестового множеств для обучения аналитической модели в условиях недостаточности исходных данных или неравномерного представления классов.

Для успешного обучения аналитической модели необходимо, чтобы классы были представлены в обучающем множестве примерно в одинаковой пропорции. Однако, если данных недостаточно или процедура ["сэмплинга"](./preprocessing/sampling.md) при формировании обучающего множества была произведена неудачно, один из классов может оказаться доминирующим. Это может вызвать "перекос" в процессе обучения, и доминирующий класс будет рассматриваться как наиболее вероятный. Метод перекрестной проверки позволяет избежать этого.

В его основе лежит разделение исходного множества данных на $$k$$ колод, например $$k=5$$. Затем на $$k-1$$, т.е. на 4-х блоках, производится обучение модели, а 5-й блок используется для тестирования. Процедура повторяется $$k$$ раз, при этом на каждом проходе для проверки выбирается новый блок, а обучение производится на оставшихся.

Перекрестная проверка имеет два основных преимущества перед применением одного множества для обучения и одного для тестирования модели:

* распределение классов оказывается более равномерным, что улучшает качество обучения;
* если при каждом проходе оценить выходную ошибку модели и усреднить ее по всем проходам, то полученная ее оценка будет более достоверной.

На практике чаще всего выбирается $$k=10$$ (10 — проходная перекрестная проверка), когда модель обучается на 9/10 данных и тестируется на 1/10. Исследования показали, что в этом случае получается наиболее достоверная оценка выходной ошибки модели.

![Метод кросс-валидации K-folds](./validation-1.svg)

### Метод Монте-Карло

 В соответствии с заданной пропорцией данные случайным образом разделяются на обучающее и валидационное множество. Модель строится на основе обучающего множества и проверяется на валидационном множестве. Процедура повторяется N раз, где N-число итераций.